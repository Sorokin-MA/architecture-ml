# Задание 1. Исследование моделей и инфраструктуры

## Сравните LLM-модели
| Критерий               | Локальные модели (Hugging Face)                     | Облачные модели (OpenAI/YandexGPT)                |  
|------------------------|----------------------------------------------------|--------------------------------------------------|  
| **Качество ответов**   | зависит от модели (например, Llama 3, Mistral) уступают GPT-4. | OpenAI GPT-4 и YandexGPT обеспечивают высокое качество, особенно в сложных задачах. Лучше работают с контекстом и сложными запросами. |  
| **Развёртывание**      | нужны знания Python, CUDA, трансформеров. Требует настройки железа (VRAM/CPU). | только API-ключ и HTTP-запросы |  
| **Стоимость**          | Относительно дешево: железо и затраты на электроэнергию | плата за токены. Для больших объёмов — дорого. |  
| **Скорость работы**    | медленно, зависит от железа. дорогое железо - дорого | высокая скорость, в облаке железо ограничено бюджетом|  
| **Конфиденциальность** | данные остаются локально — подходит для sensitive-задач. | данные в облакe — возможны риски утечек|  
| **Кастомизация**       | можно дообучать, менять архитектуру, quantize. | только prompt-инжиниринг и fine-tuning через API|  

### Сравните модели эмбеддингов

| Критерий                | Локальные модели (Sentence-Transformers)            | Облачные модели (OpenAI Embeddings)               |
|-------------------------|---------------------------------------------------|--------------------------------------------------|
| **Стоимость**          | Относительно дешево: железо и затраты на электроэнергию | плата за токены. Для больших объёмов — дорого. |  
| **Масштабируемость**    | Требует своих ресурсов для больших объёмов.       | Автоматическое масштабирование через API.         |
| **Скорость создания индекса** | Зависит от железа (CPU/GPU). На GPU скорость до сотен тысяч в минуту. | API ограничивают скорость обработки до нескольких тысяч в минуту. Зависит от бюджета |
| **Качество поиска**      | Хорошее для моделей типа `all-MiniLM-L6-v2`,уступает OpenAI для сложных задач. | Оптимизированы для разнородных данных. |
 **Конфиденциальность** | данные остаются локально — подходит для sensitive-задач. | данные в облакe — возможны риски утечек|  
| **Поддержка языков**     | Зависит от модели (есть мультиязычные, но качество варьируется). | Отличная поддержка многих языков (OpenAI оптимизирует под основные). |
| **Кастомизация**        | Можно дообучать на своих данных, менять архитектуру. | Только через fine-tuning API (у OpenAI ограничено). |

### Сравните векторные базы ChromaDB и FAISS

| Критерий                | ChromaDB                                           | FAISS                                              |
|-------------------------|---------------------------------------------------|---------------------------------------------------|
| **Мультиязычность**     | Есть клиенты для Python/JS, HTTP API.             | Только Python/C++.                                |
| **Скорость индексации** | Средняя  | Высокая, с GPU                         |
| **Скорость поиска**     | для небольших баз ~10-100 ms  | высокая 1-10 ms   |
| **Удобство работы**     | встроенные CRUD, фильтрация    | только поиск/индексация векторов |
| **Стоимость владения**  | Дешевле (можно развернуть на слабом железе).      | Дороже,нужен GPU      |
| **Сложность внедрения** | встроенный сервер, REST API            | требует интеграции в код  |
| **Persistent Storage**  | SQlite/ClickHouse              | нужно сохранять индексы вручную            |
| **Поддержка метаданных**| фильтрация по JSON-полям                | только векторный поиск                     |
| **Поддержка**           | автоматическое управление индексами      | ручной тюнинг |

### Выбор
#### Только CPU
1. FAISS
2. sentence-transformers/all-MiniLM-L6-v2
3. TheBloke/Mistral-7B-Instruct-v0.1-GGUF
4. Ryzen 9950
5. 64gb ram
6. SSD m2

#### Добавляем GPU
1. FAISS
2. bge-base-en-v1.5
3. Mixtral
4. RTX 5070
5. Ryzen 9950
6. 64gb ram
7. SSD m2

#### Cloud
1. Yandex Cloud (v100)
2. 12 core
3. 64gb ram
4. T4
5. ssd
6. YandexGPT API
7. text-embedding-3-small
8. Qdrant

Мой выбор -на CPU, так как железо у меня есть и мне было интересно развернуть всё на локальной машине.
